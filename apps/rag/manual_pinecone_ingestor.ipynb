{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the Python Requests library via pip\n",
    "# python \n",
    "# langchain \n",
    "# spacy \n",
    "# unstructured = {extras = [\"local-inference\"]}\n",
    "# layoutparser = {extras = [\"layoutmodels\", \"tesseract\"]}\n",
    "# pinecone-client\n",
    "# openai \n",
    "# torch \n",
    "# tiktoken\n",
    "# git\n",
    "\n",
    "%pip install langchain spacy unstructured[local-inference] layoutparser[layoutmodels,tesseract] pinecone-client openai torch tiktoken git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Importing necessary modules and functions:\n",
    "- os module to interact with the OS\n",
    "- Pinecone module for vector database operations\n",
    "- OpenAIEmbeddings from langchain.embeddings.openai for generating embeddings\n",
    "- SpacyTextSplitter from langchain.text_splitter for splitting text into chunks\n",
    "- Pinecone from langchain.vectorstores for storing and retrieving vectors\n",
    "- DirectoryLoader and UnstructuredFileLoader from langchain.document_loaders for loading documents from directories and unstructured files\n",
    "'''\n",
    "import os\n",
    "import pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import SpacyTextSplitter\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.document_loaders import DirectoryLoader, UnstructuredFileLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We are using Google Colab's secret manager to securely input our API keys.\n",
    "This ensures that the keys are not visible in the notebook and are not stored in the notebook's history.\n",
    "We also retrieve the Pinecone index name from the secret manager.\n",
    "'''\n",
    "from google.colab import userdata\n",
    "PINECONE_API_KEY = userdata.get('PINECONE_API_KEY')\n",
    "PINECONE_ENVIRONMENT = userdata.get('PINECONE_ENVIRONMENT')\n",
    "PINECONE_INDEX = userdata.get('PINECONE_INDEX')\n",
    "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We are defining a list of libraries from which we want to fetch the code.\n",
    "Each library is represented as a dictionary with three keys:\n",
    "  - 'name': the name of the library\n",
    "  - 'code': the URL of the library's GitHub repository\n",
    "  - 'documentation_path': the path to the documentation within the repository\n",
    "'''\n",
    "libraries = [\n",
    "    {\n",
    "        'name': 'langchain',\n",
    "        'code': 'https://github.com/langchain-ai/langchain',\n",
    "        'documentation_path': 'docs'\n",
    "    },\n",
    "    {\n",
    "        'name': 'supabase',\n",
    "        'code': 'https://github.com/supabase/supabase',\n",
    "        'documentation_path': 'master/apps/docs'\n",
    "    },\n",
    "    {\n",
    "        'name': 'next.js',\n",
    "        'code': 'https://github.com/vercel/next.js',\n",
    "        'documentation_path': 'docs'\n",
    "    },\n",
    "    {\n",
    "        'name': 'fastapi',\n",
    "        'code': 'https://github.com/tiangolo/fastapi',\n",
    "        'documentation_path': 'docs'\n",
    "    },\n",
    "    {\n",
    "        'name': 'vocode-python',\n",
    "        'code': 'https://github.com/vocodedev/vocode-python',\n",
    "        'documentation_path': 'docs'\n",
    "    }\n",
    "]\n",
    "\n",
    "'''\n",
    "The function get_code_from_github is defined to fetch the code from the GitHub repositories.\n",
    "It iterates over the libraries list and for each library, it clones the repository to a temporary directory.\n",
    "Then, it moves the documentation to a directory named 'libraries_documentation/{name}'.\n",
    "'''\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "from git import Repo\n",
    "\n",
    "def get_code_from_github():\n",
    "    # Create a temporary directory\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        for library in libraries:\n",
    "            # Clone the repository to the temporary directory\n",
    "            Repo.clone_from(library['code'], temp_dir)\n",
    "            \n",
    "            # Create a directory for the library's documentation\n",
    "            doc_dir = os.path.join('libraries_documentation', library['name'])\n",
    "            os.makedirs(doc_dir, exist_ok=True)\n",
    "            \n",
    "            # Move the documentation to the new directory\n",
    "            shutil.move(os.path.join(temp_dir, library['documentation_path']), doc_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The following code block is responsible for loading, splitting, and indexing the documents.\n",
    "'''\n",
    "\n",
    "'''\n",
    "Create a DirectoryLoader object to load all files from the 'libraries_documentation' directory.\n",
    "The glob pattern \"**/*.*\" is used to match any file in the directory or its subdirectories.\n",
    "The UnstructuredFileLoader class is used to load the files.\n",
    "'''\n",
    "loader = DirectoryLoader('./libraries_documentation', glob=\"**/*.*\", show_progress=True, loader_cls=UnstructuredFileLoader)\n",
    "\n",
    "'''\n",
    "Load the documents from the directory.\n",
    "'''\n",
    "print(\"Loading documents...\")\n",
    "documents = loader.load()\n",
    "\n",
    "'''\n",
    "Create a SpacyTextSplitter object to split the documents into chunks of 1000 characters.\n",
    "'''\n",
    "text_splitter = SpacyTextSplitter(chunk_size=1000)\n",
    "\n",
    "'''\n",
    "Split the documents into chunks.\n",
    "'''\n",
    "print(\"Splitting documents...\")\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "'''\n",
    "Create an OpenAIEmbeddings object to generate embeddings for the documents.\n",
    "'''\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "'''\n",
    "Initialize the Pinecone client with the API key and environment variables.\n",
    "'''\n",
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,\n",
    "    environment=PINECONE_ENVIRONMENT,\n",
    ")\n",
    "\n",
    "'''\n",
    "Set the name of the Pinecone index.\n",
    "'''\n",
    "index_name = PINECONE_INDEX\n",
    "\n",
    "'''\n",
    "Create a Pinecone index from the documents and their embeddings.\n",
    "'''\n",
    "print(\"Creating index...\")\n",
    "docsearch = Pinecone.from_documents(docs, embeddings, index_name=index_name)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
